{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5320cbbf",
   "metadata": {},
   "source": [
    "# Homework for Week 7\n",
    "## Functions and Downloading documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5db5b3",
   "metadata": {},
   "source": [
    "### Write modular functions for the following:\n",
    "\n",
    "1. Making a ```request```\n",
    "2. Converting a ```response``` into ```soup```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4062e0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests \n",
    "import time \n",
    "from random import randrange "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56975fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_url = \"https://sandeepmj.github.io/scrape-example-page/pages.html\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad7ae1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def request(url):\n",
    "        response = requests.get(url)\n",
    "        if 200 <= response.status_code < 400:\n",
    "            return response\n",
    "        else: \n",
    "            print(f\"Code is not working because {response.status_code}\")\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5cc061ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "request(my_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67490969",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_soup(url):\n",
    "    if response is not None and response.content:\n",
    "        return BeautifulSoup(response.text, 'html.parser')\n",
    "    else:\n",
    "        print(\"Invalid response or empty content.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c66b3f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html lang=\"en\">\n",
      " <head>\n",
      "  <!-- Makes the page responsive and scaled to be read easily -->\n",
      "  <meta content=\"width=device-width, initial-scale=1\" name=\"viewport\"/>\n",
      "  <!-- Links to stylesheet -->\n",
      "  <link href=\"style.css\" rel=\"stylesheet\" type=\"text/css\"/>\n",
      "  <!-- Remember to update page title -->\n",
      "  <title>\n",
      "   List of Documents\n",
      "  </title>\n",
      " </head>\n",
      " <body>\n",
      "  <!-- All content goes here -->\n",
      "  <div class=\"container\">\n",
      "   <h1>\n",
      "    Documents to Download\n",
      "   </h1>\n",
      "   <li>\n",
      "    Junk Li\n",
      "    <a href=\"\">\n",
      "     tag 1\n",
      "    </a>\n",
      "   </li>\n",
      "   <li>\n",
      "    Junk Li\n",
      "    <a href=\"\">\n",
      "     tag 2\n",
      "    </a>\n",
      "   </li>\n",
      "   <ul class=\"txts downloadable\">\n",
      "    <p class=\"pages\">\n",
      "     Download this first set of text documents\n",
      "    </p>\n",
      "    <li>\n",
      "     Text Document\n",
      "     <a href=\"files/text_doc_01.txt\">\n",
      "      1\n",
      "     </a>\n",
      "    </li>\n",
      "    <li>\n",
      "     Text Document\n",
      "     <a href=\"files/text_doc_02.txt\">\n",
      "      2\n",
      "     </a>\n",
      "    </li>\n",
      "    <li>\n",
      "     Text Document\n",
      "     <a href=\"files/text_doc_03.txt\">\n",
      "      3\n",
      "     </a>\n",
      "    </li>\n",
      "    <li>\n",
      "     Text Document\n",
      "     <a href=\"files/text_doc_04.txt\">\n",
      "      4\n",
      "     </a>\n",
      "    </li>\n",
      "    <li>\n",
      "     Text Document\n",
      "     <a href=\"files/text_doc_05.txt\">\n",
      "      5\n",
      "     </a>\n",
      "    </li>\n",
      "    <li>\n",
      "     Text Document\n",
      "     <a href=\"files/text_doc_06.txt\">\n",
      "      6\n",
      "     </a>\n",
      "    </li>\n",
      "    <li>\n",
      "     Text Document\n",
      "     <a href=\"files/text_doc_07.txt\">\n",
      "      7\n",
      "     </a>\n",
      "    </li>\n",
      "    <li>\n",
      "     Text Document\n",
      "     <a href=\"files/text_doc_08.txt\">\n",
      "      8\n",
      "     </a>\n",
      "    </li>\n",
      "    <li>\n",
      "     Text Document\n",
      "     <a href=\"files/text_doc_09.txt\">\n",
      "      9\n",
      "     </a>\n",
      "    </li>\n",
      "    <li>\n",
      "     Text Document\n",
      "     <a href=\"files/text_doc_10.txt\">\n",
      "      10\n",
      "     </a>\n",
      "    </li>\n",
      "   </ul>\n",
      "   <li>\n",
      "    Junk Li\n",
      "    <a href=\"\">\n",
      "     tag 3\n",
      "    </a>\n",
      "   </li>\n",
      "   <li>\n",
      "    Junk Li\n",
      "    <a href=\"\">\n",
      "     tag 4\n",
      "    </a>\n",
      "   </li>\n",
      "   <ul class=\"pdfs downloadable\">\n",
      "    <p class=\"pages\">\n",
      "     Download this list of PDFs\n",
      "    </p>\n",
      "    <li>\n",
      "     PDF Document\n",
      "     <a href=\"files/pdf_1.pdf\">\n",
      "      1\n",
      "     </a>\n",
      "    </li>\n",
      "    <li>\n",
      "     PDF Document\n",
      "     <a href=\"files/pdf_2.pdf\">\n",
      "      2\n",
      "     </a>\n",
      "    </li>\n",
      "    <li>\n",
      "     PDF Document\n",
      "     <a href=\"files/pdf_3.pdf\">\n",
      "      3\n",
      "     </a>\n",
      "    </li>\n",
      "    <li>\n",
      "     PDF Document\n",
      "     <a href=\"files/pdf_4.pdf\">\n",
      "      4\n",
      "     </a>\n",
      "    </li>\n",
      "    <li>\n",
      "     PDF Document\n",
      "     <a href=\"files/pdf_5.pdf\">\n",
      "      5\n",
      "     </a>\n",
      "    </li>\n",
      "    <li>\n",
      "     PDF Document\n",
      "     <a href=\"files/pdf_6.pdf\">\n",
      "      6\n",
      "     </a>\n",
      "    </li>\n",
      "    <li>\n",
      "     PDF Document\n",
      "     <a href=\"files/pdf_7.pdf\">\n",
      "      7\n",
      "     </a>\n",
      "    </li>\n",
      "    <li>\n",
      "     PDF Document\n",
      "     <a href=\"files/pdf_8.pdf\">\n",
      "      8\n",
      "     </a>\n",
      "    </li>\n",
      "    <li>\n",
      "     PDF Document\n",
      "     <a href=\"files/pdf_9.pdf\">\n",
      "      9\n",
      "     </a>\n",
      "    </li>\n",
      "    <li>\n",
      "     PDF Document\n",
      "     <a href=\"files/pdf_10.pdf\">\n",
      "      10\n",
      "     </a>\n",
      "    </li>\n",
      "   </ul>\n",
      "   <li>\n",
      "    Junk Li\n",
      "    <a href=\"\">\n",
      "     tag 5\n",
      "    </a>\n",
      "   </li>\n",
      "   <li>\n",
      "    Junk Li\n",
      "    <a href=\"\">\n",
      "     tag 6\n",
      "    </a>\n",
      "   </li>\n",
      "   <ul class=\"txts downloadable\">\n",
      "    <p class=\"pages\">\n",
      "     Download this second set of text documents\n",
      "    </p>\n",
      "    <li>\n",
      "     Text Document\n",
      "     <a href=\"files/text_doc_A.txt\">\n",
      "      1\n",
      "     </a>\n",
      "    </li>\n",
      "    <li>\n",
      "     Text Document\n",
      "     <a href=\"files/text_doc_B.txt\">\n",
      "      2\n",
      "     </a>\n",
      "    </li>\n",
      "    <li>\n",
      "     Text Document\n",
      "     <a href=\"files/text_doc_C.txt\">\n",
      "      3\n",
      "     </a>\n",
      "    </li>\n",
      "    <li>\n",
      "     Text Document\n",
      "     <a href=\"files/text_doc_D.txt\">\n",
      "      4\n",
      "     </a>\n",
      "    </li>\n",
      "    <li>\n",
      "     Text Document\n",
      "     <a href=\"files/text_doc_E.txt\">\n",
      "      5\n",
      "     </a>\n",
      "    </li>\n",
      "    <li>\n",
      "     Text Document\n",
      "     <a href=\"files/text_doc_F.txt\">\n",
      "      6\n",
      "     </a>\n",
      "    </li>\n",
      "    <li>\n",
      "     Text Document\n",
      "     <a href=\"files/text_doc_G.txt\">\n",
      "      7\n",
      "     </a>\n",
      "    </li>\n",
      "    <li>\n",
      "     Text Document\n",
      "     <a href=\"files/text_doc_H.txt\">\n",
      "      8\n",
      "     </a>\n",
      "    </li>\n",
      "    <li>\n",
      "     Text Document\n",
      "     <a href=\"files/text_doc_I.txt\">\n",
      "      9\n",
      "     </a>\n",
      "    </li>\n",
      "    <li>\n",
      "     Text Document\n",
      "     <a href=\"files/text_doc_J.txt\">\n",
      "      10\n",
      "     </a>\n",
      "    </li>\n",
      "   </ul>\n",
      "  </div>\n",
      " </body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = request(my_url)\n",
    "if response:\n",
    "    soup = get_soup(response)\n",
    "    if soup:\n",
    "        print(soup.prettify())  # Print the prettified HTML\n",
    "else:\n",
    "    print(\"Code is not working.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2350b62c",
   "metadata": {},
   "source": [
    "### 3. Demo downloading files from websites \n",
    "\n",
    "There are ```txt``` and ```pdf``` files <a href=\"https://sandeepmj.github.io/scrape-example-page/pages.html\">on this site</a>. During class we downloaded on e set of text files and one set of PDF files.\n",
    "\n",
    "Now download **ALL files at one time**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a209478",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://sandeepmj.github.io/scrape-example-page/pages.html\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "base_url = \"https://sandeepmj.github.io/scrape-example-page/page/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "87e10706",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<ul class=\"txts downloadable\">\n",
       " <p class=\"pages\">Download this first set of text documents</p>\n",
       " <li>Text Document <a href=\"files/text_doc_01.txt\">1</a> </li>\n",
       " <li>Text Document <a href=\"files/text_doc_02.txt\">2</a></li>\n",
       " <li>Text Document <a href=\"files/text_doc_03.txt\">3</a></li>\n",
       " <li>Text Document <a href=\"files/text_doc_04.txt\">4</a></li>\n",
       " <li>Text Document <a href=\"files/text_doc_05.txt\">5</a></li>\n",
       " <li>Text Document <a href=\"files/text_doc_06.txt\">6</a></li>\n",
       " <li>Text Document <a href=\"files/text_doc_07.txt\">7</a></li>\n",
       " <li>Text Document <a href=\"files/text_doc_08.txt\">8</a></li>\n",
       " <li>Text Document <a href=\"files/text_doc_09.txt\">9</a></li>\n",
       " <li>Text Document <a href=\"files/text_doc_10.txt\">10</a></li>\n",
       " </ul>,\n",
       " <ul class=\"pdfs downloadable\">\n",
       " <p class=\"pages\">Download this list of PDFs</p>\n",
       " <li>PDF Document <a href=\"files/pdf_1.pdf\">1</a> </li>\n",
       " <li>PDF Document <a href=\"files/pdf_2.pdf\">2</a></li>\n",
       " <li>PDF Document <a href=\"files/pdf_3.pdf\">3</a></li>\n",
       " <li>PDF Document <a href=\"files/pdf_4.pdf\">4</a></li>\n",
       " <li>PDF Document <a href=\"files/pdf_5.pdf\">5</a></li>\n",
       " <li>PDF Document <a href=\"files/pdf_6.pdf\">6</a></li>\n",
       " <li>PDF Document <a href=\"files/pdf_7.pdf\">7</a></li>\n",
       " <li>PDF Document <a href=\"files/pdf_8.pdf\">8</a></li>\n",
       " <li>PDF Document <a href=\"files/pdf_9.pdf\">9</a></li>\n",
       " <li>PDF Document <a href=\"files/pdf_10.pdf\">10</a></li>\n",
       " </ul>,\n",
       " <ul class=\"txts downloadable\">\n",
       " <p class=\"pages\">Download this second set of text documents</p>\n",
       " <li>Text Document <a href=\"files/text_doc_A.txt\">1</a> </li>\n",
       " <li>Text Document <a href=\"files/text_doc_B.txt\">2</a></li>\n",
       " <li>Text Document <a href=\"files/text_doc_C.txt\">3</a></li>\n",
       " <li>Text Document <a href=\"files/text_doc_D.txt\">4</a></li>\n",
       " <li>Text Document <a href=\"files/text_doc_E.txt\">5</a></li>\n",
       " <li>Text Document <a href=\"files/text_doc_F.txt\">6</a></li>\n",
       " <li>Text Document <a href=\"files/text_doc_G.txt\">7</a></li>\n",
       " <li>Text Document <a href=\"files/text_doc_H.txt\">8</a></li>\n",
       " <li>Text Document <a href=\"files/text_doc_I.txt\">9</a></li>\n",
       " <li>Text Document <a href=\"files/text_doc_J.txt\">10</a></li>\n",
       " </ul>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl_all = soup.find_all(\"ul\")\n",
    "dl_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f434ea32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<ul class=\"txts downloadable\">\n",
       " <p class=\"pages\">Download this first set of text documents</p>\n",
       " <li>Text Document <a href=\"files/text_doc_01.txt\">1</a> </li>\n",
       " <li>Text Document <a href=\"files/text_doc_02.txt\">2</a></li>\n",
       " <li>Text Document <a href=\"files/text_doc_03.txt\">3</a></li>\n",
       " <li>Text Document <a href=\"files/text_doc_04.txt\">4</a></li>\n",
       " <li>Text Document <a href=\"files/text_doc_05.txt\">5</a></li>\n",
       " <li>Text Document <a href=\"files/text_doc_06.txt\">6</a></li>\n",
       " <li>Text Document <a href=\"files/text_doc_07.txt\">7</a></li>\n",
       " <li>Text Document <a href=\"files/text_doc_08.txt\">8</a></li>\n",
       " <li>Text Document <a href=\"files/text_doc_09.txt\">9</a></li>\n",
       " <li>Text Document <a href=\"files/text_doc_10.txt\">10</a></li>\n",
       " </ul>,\n",
       " <ul class=\"txts downloadable\">\n",
       " <p class=\"pages\">Download this second set of text documents</p>\n",
       " <li>Text Document <a href=\"files/text_doc_A.txt\">1</a> </li>\n",
       " <li>Text Document <a href=\"files/text_doc_B.txt\">2</a></li>\n",
       " <li>Text Document <a href=\"files/text_doc_C.txt\">3</a></li>\n",
       " <li>Text Document <a href=\"files/text_doc_D.txt\">4</a></li>\n",
       " <li>Text Document <a href=\"files/text_doc_E.txt\">5</a></li>\n",
       " <li>Text Document <a href=\"files/text_doc_F.txt\">6</a></li>\n",
       " <li>Text Document <a href=\"files/text_doc_G.txt\">7</a></li>\n",
       " <li>Text Document <a href=\"files/text_doc_H.txt\">8</a></li>\n",
       " <li>Text Document <a href=\"files/text_doc_I.txt\">9</a></li>\n",
       " <li>Text Document <a href=\"files/text_doc_J.txt\">10</a></li>\n",
       " </ul>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt_class = soup.find_all(\"ul\", class_=\"txts\")\n",
    "txt_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "590e7502",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a href=\"files/pdf_1.pdf\">1</a>,\n",
       " <a href=\"files/pdf_2.pdf\">2</a>,\n",
       " <a href=\"files/pdf_3.pdf\">3</a>,\n",
       " <a href=\"files/pdf_4.pdf\">4</a>,\n",
       " <a href=\"files/pdf_5.pdf\">5</a>,\n",
       " <a href=\"files/pdf_6.pdf\">6</a>,\n",
       " <a href=\"files/pdf_7.pdf\">7</a>,\n",
       " <a href=\"files/pdf_8.pdf\">8</a>,\n",
       " <a href=\"files/pdf_9.pdf\">9</a>,\n",
       " <a href=\"files/pdf_10.pdf\">10</a>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aTags = soup.find(\"ul\", class_=\"pdfs\").find_all(\"a\")\n",
    "aTags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dca6f900",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a href=\"files/pdf_1.pdf\">1</a>,\n",
       " <a href=\"files/pdf_2.pdf\">2</a>,\n",
       " <a href=\"files/pdf_3.pdf\">3</a>,\n",
       " <a href=\"files/pdf_4.pdf\">4</a>,\n",
       " <a href=\"files/pdf_5.pdf\">5</a>,\n",
       " <a href=\"files/pdf_6.pdf\">6</a>,\n",
       " <a href=\"files/pdf_7.pdf\">7</a>,\n",
       " <a href=\"files/pdf_8.pdf\">8</a>,\n",
       " <a href=\"files/pdf_9.pdf\">9</a>,\n",
       " <a href=\"files/pdf_10.pdf\">10</a>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aTags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "67260921",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://sandeepmj.github.io/scrape-example-page/page/files/pdf_1.pdf',\n",
       " 'https://sandeepmj.github.io/scrape-example-page/page/files/pdf_2.pdf',\n",
       " 'https://sandeepmj.github.io/scrape-example-page/page/files/pdf_3.pdf',\n",
       " 'https://sandeepmj.github.io/scrape-example-page/page/files/pdf_4.pdf',\n",
       " 'https://sandeepmj.github.io/scrape-example-page/page/files/pdf_5.pdf',\n",
       " 'https://sandeepmj.github.io/scrape-example-page/page/files/pdf_6.pdf',\n",
       " 'https://sandeepmj.github.io/scrape-example-page/page/files/pdf_7.pdf',\n",
       " 'https://sandeepmj.github.io/scrape-example-page/page/files/pdf_8.pdf',\n",
       " 'https://sandeepmj.github.io/scrape-example-page/page/files/pdf_9.pdf',\n",
       " 'https://sandeepmj.github.io/scrape-example-page/page/files/pdf_10.pdf']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links = [base_url + aTag.get(\"href\") for aTag in aTags]\n",
    "links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "508d47a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wget in /Users/benedettatommaselli/anaconda3/lib/python3.11/site-packages (3.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6d010354",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d6aaf096",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from random import randrange\n",
    "def snoozer(low_number, high_number):\n",
    "    snoozer = randrange(low_number, high_number)\n",
    "    print(f\"snoozing for {snoozer} seconds before next scrape\")\n",
    "    time.sleep(snoozer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9b980b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading link 1 of 10\n"
     ]
    },
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 404: Not Found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m     link_count\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m##downloading docs\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m     wget\u001b[38;5;241m.\u001b[39mdownload(link)\n\u001b[1;32m      9\u001b[0m     snoozer(start_range, end_range)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDone downloading \u001b[39m\u001b[38;5;132;01m{link_count}\u001b[39;00m\u001b[38;5;124m if \u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124mlen(links)}\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wget.py:526\u001b[0m, in \u001b[0;36mdownload\u001b[0;34m(url, out, bar)\u001b[0m\n\u001b[1;32m    524\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    525\u001b[0m     binurl \u001b[38;5;241m=\u001b[39m url\n\u001b[0;32m--> 526\u001b[0m (tmpfile, headers) \u001b[38;5;241m=\u001b[39m ulib\u001b[38;5;241m.\u001b[39murlretrieve(binurl, tmpfile, callback)\n\u001b[1;32m    527\u001b[0m filename \u001b[38;5;241m=\u001b[39m detect_filename(url, out, headers)\n\u001b[1;32m    528\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m outdir:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/urllib/request.py:241\u001b[0m, in \u001b[0;36murlretrieve\u001b[0;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;124;03mRetrieve a URL into a temporary location on disk.\u001b[39;00m\n\u001b[1;32m    226\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;124;03mdata file as well as the resulting HTTPMessage object.\u001b[39;00m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    239\u001b[0m url_type, path \u001b[38;5;241m=\u001b[39m _splittype(url)\n\u001b[0;32m--> 241\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mclosing(urlopen(url, data)) \u001b[38;5;28;01mas\u001b[39;00m fp:\n\u001b[1;32m    242\u001b[0m     headers \u001b[38;5;241m=\u001b[39m fp\u001b[38;5;241m.\u001b[39minfo()\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;66;03m# Just return the local path and the \"headers\" for file://\u001b[39;00m\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;66;03m# URLs. No sense in performing a copy unless requested.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/urllib/request.py:216\u001b[0m, in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    215\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[0;32m--> 216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m opener\u001b[38;5;241m.\u001b[39mopen(url, data, timeout)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/urllib/request.py:525\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m processor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_response\u001b[38;5;241m.\u001b[39mget(protocol, []):\n\u001b[1;32m    524\u001b[0m     meth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(processor, meth_name)\n\u001b[0;32m--> 525\u001b[0m     response \u001b[38;5;241m=\u001b[39m meth(req, response)\n\u001b[1;32m    527\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/urllib/request.py:634\u001b[0m, in \u001b[0;36mHTTPErrorProcessor.http_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;66;03m# According to RFC 2616, \"2xx\" code indicates that the client's\u001b[39;00m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;66;03m# request was successfully received, understood, and accepted.\u001b[39;00m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m):\n\u001b[0;32m--> 634\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparent\u001b[38;5;241m.\u001b[39merror(\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp\u001b[39m\u001b[38;5;124m'\u001b[39m, request, response, code, msg, hdrs)\n\u001b[1;32m    637\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/urllib/request.py:563\u001b[0m, in \u001b[0;36mOpenerDirector.error\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_err:\n\u001b[1;32m    562\u001b[0m     args \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mdict\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp_error_default\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m+\u001b[39m orig_args\n\u001b[0;32m--> 563\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_chain(\u001b[38;5;241m*\u001b[39margs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/urllib/request.py:496\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[1;32m    495\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[0;32m--> 496\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m    497\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    498\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/urllib/request.py:643\u001b[0m, in \u001b[0;36mHTTPDefaultErrorHandler.http_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    642\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhttp_error_default\u001b[39m(\u001b[38;5;28mself\u001b[39m, req, fp, code, msg, hdrs):\n\u001b[0;32m--> 643\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(req\u001b[38;5;241m.\u001b[39mfull_url, code, msg, hdrs, fp)\n",
      "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 404: Not Found"
     ]
    }
   ],
   "source": [
    "link_count = 1\n",
    "start_range, end_range = 10, 21\n",
    "\n",
    "for link in links:\n",
    "    print(f\"Downloading link {link_count} of {len(links)}\")\n",
    "    link_count+=1\n",
    "    ##downloading docs\n",
    "    wget.download(link)\n",
    "    snoozer(start_range, end_range)\n",
    "print(\"Done downloading {link_count} if {len(links)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d541d79f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
